{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cezuUt4GvP3H"
   },
   "source": [
    "# Assignment 3: Build a seq2seq model for machine translation.\n",
    "\n",
    "### Name: Aughdon Breslin\n",
    "\n",
    "### Task: Change LSTM model to Bidirectional LSTM Modelï¼Œ translate English to target language and evaluate using Bleu score.\n",
    "\n",
    "### Due Date: Tuesday, April 19th, 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULuIrJcKvP3L"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read and run the code. Please make sure you have installed keras or tensorflow.Running the script on colab will speed up the training process and also prevent package loading issue. \n",
    "2. Complete the code in Section 1.1, you may fill in your data directory.\n",
    "3. Directly modify the code in Section 3. Change the current LSTM layer to a Bidirectional LSTM Model.\n",
    "4. Training your model and translate English to Spanish in Section 4.2. You could try translating other languages.\n",
    "5. Complete the code in Section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38BXEC1NvP3M"
   },
   "source": [
    "### Hint: \n",
    "\n",
    "To implement ```Bi-LSTM```, you will need the following code to build the encoder. Do NOT use Bi-LSTM for the decoder. But there are other codes you need to modify to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TGHt6vGgvP3N"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy\n",
    "\n",
    "from keras.layers import Input, LSTM, Bidirectional, Concatenate, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bye_hdZ2vP3P"
   },
   "source": [
    "## 1. Data preparation (10 points)\n",
    "\n",
    "1. Download spanish-english data from http://www.manythings.org/anki/\n",
    "2. You may try to use other languages.\n",
    "3. Unzip the .ZIP file.\n",
    "4. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\".\n",
    "5. Fill in your data directory in section 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj1OVqDsvP3Q"
   },
   "source": [
    "### 1.1. Load and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t1jICbpbvP3R"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s_P3fFtvP3S"
   },
   "source": [
    "#### Fill the following blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FyMlb2FwvP3T"
   },
   "outputs": [],
   "source": [
    "# e.g., filename = 'Data/deu.txt'\n",
    "filename = 'Data/spa.txt'\n",
    "\n",
    "# e.g., n_train = 20000\n",
    "n_train = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Aq_bTykqvP3U"
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "doc = load_doc(filename)\n",
    "\n",
    "# split into Language1-Language2 pairs\n",
    "pairs = to_pairs(doc)\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_data(pairs)[0:n_train, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myKZDKvlvP3V",
    "outputId": "18e25852-7195-4306-dea2-fa36d70dfe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youre here] => [estas aqui]\n",
      "[youre here] => [estais aqui]\n",
      "[youre late] => [estas retrasado]\n",
      "[youre lost] => [estas perdido]\n",
      "[youre mean] => [eres mala]\n",
      "[youre mean] => [eres mezquino]\n",
      "[youre mine] => [tu eres mio]\n",
      "[youre nice] => [eres simpatico]\n",
      "[youre nuts] => [estas loco]\n",
      "[youre nuts] => [estas chiflado]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000, 3010):\n",
    "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-ouQtvVvP3W",
    "outputId": "b9b2e584-0587-4a18-ed16-78732c73dbc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (20000,)\n",
      "Length of target_texts: (20000,)\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMmWSJUVvP3X",
    "outputId": "28c97282-768b-4f25-b502-c8c31a5714a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input  sentences: 18\n",
      "max length of target sentences: 55\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_P16ZzqvP3a"
   },
   "source": [
    "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbhr8s-XvP3b"
   },
   "source": [
    "## 2. Text processing\n",
    "\n",
    "### 2.1. Convert texts to sequences\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O18mfxHivP3b",
    "outputId": "12dbf4ea-f28f-4b15-8651-5e0433b31e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (20000, 18)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (20000, 55)\n",
      "shape of target_token_index: 29\n"
     ]
    }
   ],
   "source": [
    "# encode and pad sequences\n",
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gwt6SE8ovP3f",
    "outputId": "6ab9e26b-3cdd-4d27-b519-b2d6f0402ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se8uiEBlvP3i"
   },
   "source": [
    "**Remark:** To this end, the input language and target language texts are converted to 2 matrices. \n",
    "\n",
    "- Their number of rows are both n_train.\n",
    "- Their number of columns are respective max_encoder_seq_length and max_decoder_seq_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muVzGjyVvP3i"
   },
   "source": [
    "The followings print a sentence and its representation as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XsF3hbxIvP3j",
    "outputId": "27a00d82-e6b5-4736-b1d3-b993170f4e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tno puede ser\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP_b01VovP3k",
    "outputId": "cff1588f-8824-4567-a055-4dafb820a438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  3,  1, 17, 14,  2, 15,  2,  1,  5,  2, 10,  7,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_seq[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB8f4tJbvP3m"
   },
   "source": [
    "## 2.2. One-hot encode\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding.\n",
    "- It is represented by a $n\\times t \\times v$ tensor ($t$ is the number of unique chars) after the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THIFj9TuvP3m",
    "outputId": "718edde7-ce00-4f71-bf83-279e69306c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 18, 28)\n",
      "(20000, 55, 30)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode target sequence\n",
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = numpy.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data\n",
    "\n",
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FXXIgAWvP3n"
   },
   "source": [
    "## 3. Build the networks (for training) (20 points)\n",
    "\n",
    "- In this section, we have already implemented the LSTM model for you. You can run the code and see what the code is doing.  \n",
    "\n",
    "- You need to change the existing LSTM model to a Bidirectional LSTM model. Just modify the network structrue and do not change the training cell in section 3.4.\n",
    "\n",
    "- Build encoder, decoder, and connect the two modules to get \"model\". \n",
    "\n",
    "- Fit the model on the bilingual data to train the parameters in the encoder and decoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O76Luk4hvP3o"
   },
   "source": [
    "### 3.1. Encoder network\n",
    "\n",
    "- Input:  one-hot encode of the input language\n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states   $h_1, \\cdots , h_t$) are always discarded\n",
    "    \n",
    "    -- the final hidden state  $h_t$\n",
    "    \n",
    "    -- the final conveyor belt $c_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DdzBBsBovP3p"
   },
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "# set the LSTM layer\n",
    "encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "                                  dropout=0.5, name='encoder_lstm'))\n",
    "_, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_h, state_c],\n",
    "                      name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK9l2RJvvP3p"
   },
   "source": [
    "Print a summary and save the encoder network structure to \"./encoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnwD8pnVvP3q",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIZf8mwkvP3s",
    "outputId": "40f7dfdf-fb5f-45db-e748-d5300ed1a1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 512), (None, 583680      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "==================================================================================================\n",
      "Total params: 583,680\n",
      "Trainable params: 583,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=encoder_model, show_shapes=False,\n",
    "    to_file='encoder.pdf'\n",
    ")\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR8V6tOWvP3t"
   },
   "source": [
    "### 3.2. Decoder network\n",
    "\n",
    "- Inputs:  \n",
    "\n",
    "    -- one-hot encode of the target language\n",
    "    \n",
    "    -- The initial hidden state $h_t$ \n",
    "    \n",
    "    -- The initial conveyor belt $c_t$ \n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states) $h_1, \\cdots , h_t$\n",
    "\n",
    "    -- the final hidden state  $h_t$ (discarded in the training and used in the prediction)\n",
    "    \n",
    "    -- the final conveyor belt $c_t$ (discarded in the training and used in the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UGs82eJFvP3u"
   },
   "outputs": [],
   "source": [
    "# inputs of the decoder network\n",
    "decoder_input_h = Input(shape=(latent_dim*2,), name='decoder_input_h')\n",
    "decoder_input_c = Input(shape=(latent_dim*2,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, \n",
    "                    return_state=True, dropout=0.5, name='decoder_lstm')\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, \n",
    "                                                      initial_state=[decoder_input_h, decoder_input_c])\n",
    "\n",
    "# set the dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                      outputs=[decoder_outputs, state_h, state_c],\n",
    "                      name='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4qYXYxlvP3v"
   },
   "source": [
    "Print a summary and save the encoder network structure to \"./decoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rutWtKqOvP3w",
    "outputId": "3529ac6f-cab5-4afa-eda6-d81283ed406a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,127,454\n",
      "Trainable params: 1,127,454\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=decoder_model, show_shapes=False,\n",
    "    to_file='decoder.pdf'\n",
    ")\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKjzAsdivP3x"
   },
   "source": [
    "### 3.3. Connect the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XYVOblhDvP3y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_Sv909pvP3y",
    "outputId": "a35f6678-991b-4626-c68a-a4f507872355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,711,134\n",
      "Trainable params: 1,711,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=model, show_shapes=False,\n",
    "    to_file='model_training.pdf'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-9Bbj3fvP30"
   },
   "source": [
    "### 3.4. Fit the model on the bilingual dataset\n",
    "\n",
    "- encoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_target_data: labels (left shift of decoder_input_data)\n",
    "\n",
    "- tune the hyper-parameters\n",
    "\n",
    "- stop when the validation loss stop decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Vas3rr9vP30",
    "outputId": "9029e6bc-46ac-4c25-ee32-414e41301eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_data(20000, 18, 28)\n",
      "shape of decoder_input_data(20000, 55, 30)\n",
      "shape of decoder_target_data(20000, 55, 30)\n"
     ]
    }
   ],
   "source": [
    "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
    "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
    "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuFeHtsHvP31",
    "outputId": "6fa6d1a5-1fec-49fa-92cb-785f8df5cf1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "250/250 [==============================] - 167s 654ms/step - loss: 0.9199 - val_loss: 0.8113\n",
      "Epoch 2/16\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 0.7134 - val_loss: 0.7294\n",
      "Epoch 3/16\n",
      "250/250 [==============================] - 101s 406ms/step - loss: 0.6731 - val_loss: 0.6707\n",
      "Epoch 4/16\n",
      "250/250 [==============================] - 104s 414ms/step - loss: 0.6443 - val_loss: 0.6353\n",
      "Epoch 5/16\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 0.6205 - val_loss: 0.6111\n",
      "Epoch 6/16\n",
      "250/250 [==============================] - 106s 423ms/step - loss: 0.6037 - val_loss: 0.5880\n",
      "Epoch 7/16\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 0.5876 - val_loss: 0.5751\n",
      "Epoch 8/16\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 0.5758 - val_loss: 0.5560\n",
      "Epoch 9/16\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 0.5623 - val_loss: 0.5474\n",
      "Epoch 10/16\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 0.5517 - val_loss: 0.5330\n",
      "Epoch 11/16\n",
      "250/250 [==============================] - 108s 434ms/step - loss: 0.5413 - val_loss: 0.5245\n",
      "Epoch 12/16\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.5324 - val_loss: 0.5139\n",
      "Epoch 13/16\n",
      "250/250 [==============================] - 104s 415ms/step - loss: 0.5238 - val_loss: 0.5056\n",
      "Epoch 14/16\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 0.5158 - val_loss: 0.4979\n",
      "Epoch 15/16\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.5077 - val_loss: 0.4979\n",
      "Epoch 16/16\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.5026 - val_loss: 0.4852\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "          batch_size=64, epochs=16, validation_split=0.2)\n",
    "\n",
    "model.save('seq2seq.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpY1O3FAvP32"
   },
   "source": [
    "## 4. Make predictions\n",
    "\n",
    "- In this section, you need to complete section 4.2 to translate English to the target language.\n",
    "\n",
    "\n",
    "### 4.1. Translate English to XXX\n",
    "\n",
    "1. Encoder read a sentence (source language) and output its final states, $h_t$ and $c_t$.\n",
    "2. Take the [star] sign \"\\t\" and the final state $h_t$ and $c_t$ as input and run the decoder.\n",
    "3. Get the new states and predicted probability distribution.\n",
    "4. sample a char from the predicted probability distribution\n",
    "5. take the sampled char and the new states as input and repeat the process (stop if reach the [stop] sign \"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "G8LjKP1ZvP32"
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KwcoNcPzvP32"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # this line of code is greedy selection\n",
    "        # try to use multinomial sampling instead (with temperature)\n",
    "        sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQ9r_1JdvP34",
    "outputId": "b8e10459-ac34-4ef0-8bb3-55f87bae76cf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "English:        hes skinny\n",
      "Spanish (true):  el esta delgado\n",
      "Spanish (pred):  el es a ententado\n",
      "-\n",
      "English:        hes strong\n",
      "Spanish (true):  el es fuerte\n",
      "Spanish (pred):  el es a andiendo\n",
      "-\n",
      "English:        hes stupid\n",
      "Spanish (true):  el es estupido\n",
      "Spanish (pred):  el es a anuerdo\n",
      "-\n",
      "English:        hes stupid\n",
      "Spanish (true):  no le llega agua al tanque\n",
      "Spanish (pred):  el es a anuerdo\n",
      "-\n",
      "English:        hes stupid\n",
      "Spanish (true):  es un salame\n",
      "Spanish (pred):  el es a anuerdo\n",
      "-\n",
      "English:        help me out\n",
      "Spanish (true):  ayudame\n",
      "Spanish (pred):  ayudame a la cara\n",
      "-\n",
      "English:        help me out\n",
      "Spanish (true):  ayudame a salir\n",
      "Spanish (pred):  ayudame a la cara\n",
      "-\n",
      "English:        help me out\n",
      "Spanish (true):  echeme la mano\n",
      "Spanish (pred):  ayudame a la cara\n",
      "-\n",
      "English:        help me out\n",
      "Spanish (true):  ayudame a salir\n",
      "Spanish (pred):  ayudame a la cara\n",
      "-\n",
      "English:        here i come\n",
      "Spanish (true):  aqui vengo\n",
      "Spanish (pred):  aqui esta el casa\n",
      "-\n",
      "English:        here i come\n",
      "Spanish (true):  ya estoy aqui\n",
      "Spanish (pred):  aqui esta el casa\n",
      "-\n",
      "English:        here she is\n",
      "Spanish (true):  aqui esta ella\n",
      "Spanish (pred):  aqui esta es o\n",
      "-\n",
      "English:        here we are\n",
      "Spanish (true):  aqui estamos\n",
      "Spanish (pred):  aqui estamos aqui\n",
      "-\n",
      "English:        here we are\n",
      "Spanish (true):  aqui estamos\n",
      "Spanish (pred):  aqui estamos aqui\n",
      "-\n",
      "English:        hi im tom\n",
      "Spanish (true):  hola soy tom\n",
      "Spanish (pred):  es es a mary\n",
      "-\n",
      "English:        hit it hard\n",
      "Spanish (true):  dele fuerte\n",
      "Spanish (pred):  esta es alante\n",
      "-\n",
      "English:        how are you\n",
      "Spanish (true):  como estas vos\n",
      "Spanish (pred):  como estas tu sado\n",
      "-\n",
      "English:        how curious\n",
      "Spanish (true):  que curioso\n",
      "Spanish (pred):  que tal tan te\n",
      "-\n",
      "English:        how strange\n",
      "Spanish (true):  que raro\n",
      "Spanish (pred):  que alora\n",
      "-\n",
      "English:        how strange\n",
      "Spanish (true):  que raro\n",
      "Spanish (pred):  que alora\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(2100, 2120):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('English:       ', input_texts[seq_index])\n",
    "    print('Spanish (true): ', target_texts[seq_index][1:-1])\n",
    "    print('Spanish (pred): ', decoded_sentence[0:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwGL3heRvP36"
   },
   "source": [
    "### 4.2. Translate an English sentence to the target language ï¼ˆ20 pointsï¼‰\n",
    "\n",
    "1. Tokenization\n",
    "2. One-hot encode\n",
    "3. Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z0ULnr4vP38",
    "outputId": "06588ded-d5ce-4f87-e898-5c0449ae251c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source sentence is: I love you\n",
      "translated sentence is: tom esta aqui\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'I love you'\n",
    "\n",
    "input_sequence, _ = text2sequences(max_encoder_seq_length, [input_sentence])\n",
    "\n",
    "input_x = onehot_encode(input_sequence, max_encoder_seq_length, num_encoder_tokens)\n",
    "\n",
    "translated_sentence = decode_sequence(input_x)\n",
    "\n",
    "print('source sentence is: ' + input_sentence)\n",
    "print('translated sentence is: ' + translated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACwqjZLmvP3_"
   },
   "source": [
    "# 5. Evaluate the translation using BLEU score\n",
    "\n",
    "- We have already translated from English to target language, but how can we evaluate the performance of our model quantitatively? \n",
    "\n",
    "- In this section, you need to re-train the model we built in secton 3 and then evaluate the bleu score on testing dataset.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "\n",
    "https://en.wikipedia.org/wiki/BLEU\n",
    "\n",
    "#### Hint:\n",
    "- You may use packages to calculate bleu score, e.g., sentence_bleu() from nltk package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruUUT53TvP3_"
   },
   "source": [
    "### 5.1. Partition the dataset to training, validation, and test. Build new token index. (10 points)\n",
    "\n",
    "1. You may try to load more data/lines from text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9THAG16mIOoO"
   },
   "source": [
    "- Randomly partition the dataset to training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvpG15rSvP4A",
    "outputId": "2470160c-c229-4d20-c282-cece2e92b2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Encoder Sequence Length: 9\n",
      "Max Decoder Sequence Length: 30\n"
     ]
    }
   ],
   "source": [
    "clean_pairs = clean_data(pairs)[0:1000, :]\n",
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print(\"Max Encoder Sequence Length:\", max_encoder_seq_length)\n",
    "print(\"Max Decoder Sequence Length:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x_train:  (800,)\n",
      "Length of x_test: (200,)\n",
      "Length of y_train:  800\n",
      "Length of y_test: 200\n",
      "['i can run' 'take tom' 'get lost' 'take care']\n",
      "['\\tpuedo correr\\n', '\\tllevate a tom\\n', '\\tlargate\\n', '\\tte cuidas\\n']\n",
      "['thank you' 'keep this' 'back off' 'who came']\n",
      "['\\tgracias a ti\\n', '\\tguarde esto\\n', '\\taparta\\n', '\\tquien vino\\n']\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_texts, target_texts, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('Length of x_train:  ' + str(x_train.shape))\n",
    "print('Length of x_test: ' + str(x_test.shape))\n",
    "\n",
    "print('Length of y_train:  ' + str(len(y_train)))\n",
    "print('Length of y_test: ' + str(len(y_test)))\n",
    "\n",
    "print(x_train[:4])\n",
    "print(y_train[:4])\n",
    "print(x_test[:4])\n",
    "print(y_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9VPWsWjvP4A",
    "outputId": "9ad60b8a-6ffc-4a6b-8cd6-dbc037d0f945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x_tr:  (640,)\n",
      "Length of x_val: (160,)\n",
      "Length of y_tr:  640\n",
      "Length of y_val: 160\n",
      "['help me' 'keep warm' 'it rained' 'i hate it']\n",
      "['\\tayudame\\n', '\\tmantente abrigado\\n', '\\tllovio\\n', '\\tme la baja\\n']\n",
      "['i am old' 'who won' 'i talked' 'use this']\n",
      "['\\testoy viejo\\n', '\\tquien gano\\n', '\\thable\\n', '\\tusa esto\\n']\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('Length of x_tr:  ' + str(x_tr.shape))\n",
    "print('Length of x_val: ' + str(x_val.shape))\n",
    "\n",
    "print('Length of y_tr:  ' + str(len(y_tr)))\n",
    "print('Length of y_val: ' + str(len(y_val)))\n",
    "\n",
    "print(x_tr[:4])\n",
    "print(y_tr[:4])\n",
    "print(x_val[:4])\n",
    "print(y_val[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zit73eiIIZqj"
   },
   "source": [
    "\n",
    "- Evaluate the BLEU score using the test set. Report the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUGLBqwYExCd",
    "outputId": "1e5d7a4b-c330-48a1-ecc4-37464df2fa75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score using the test set: 0.22661638275724968\n"
     ]
    }
   ],
   "source": [
    "score = 0;\n",
    "for i, sentence in enumerate(x_test):\n",
    "  input_sequence, _ = text2sequences(max_encoder_seq_length, [sentence])\n",
    "  input_x = onehot_encode(input_sequence, max_encoder_seq_length, num_encoder_tokens)\n",
    "  translated_sentence = decode_sequence(input_x)\n",
    "  score += sentence_bleu(translated_sentence,y_test[i],[1])\n",
    "  # print(\"Sentence:\", sentence, \"Translation:\", translated_sentence, \"True:\", y_test[i], \"Score:\", sentence_bleu(translated_sentence,y_test[i],[1]))\n",
    "score /= len(x_test)\n",
    "print(\"Average BLEU Score using the test set:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert text to sequences and build token index using training data.\n",
    "3. One-hot encode your training and validation text sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoder_input_seq, x_train_input_token_index = text2sequences(max_encoder_seq_length, x_train)\n",
    "y_train_decoder_input_seq, y_train_target_token_index = text2sequences(max_decoder_seq_length, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 28\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(x_train_input_token_index) + 1\n",
    "num_decoder_tokens = len(y_train_target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_input_data = onehot_encode(x_train_encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "y_train_input_data = onehot_encode(y_train_decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "# encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "# decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train sequence vs orig encoder sequence: (800, 9) (20000, 18)\n",
      "y_train sequence vs orig decoder sequence: (800, 30) (20000, 55)\n",
      "x_train input vs orig encoder input data: (800, 9, 28) (20000, 18, 28)\n",
      "y_train input vs orig decoder input data: (800, 30, 28) (20000, 55, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train sequence vs orig encoder sequence:\", x_train_encoder_input_seq.shape, encoder_input_seq.shape)\n",
    "print(\"y_train sequence vs orig decoder sequence:\", y_train_decoder_input_seq.shape, decoder_input_seq.shape)\n",
    "\n",
    "print(\"x_train input vs orig encoder input data:\", x_train_input_data.shape, encoder_input_data.shape)\n",
    "print(\"y_train input vs orig decoder input data:\", y_train_input_data.shape, decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_decoder_target_seq = numpy.zeros(y_train_decoder_input_seq.shape)\n",
    "y_train_decoder_target_seq[:, 0:-1] = y_train_decoder_input_seq[:, 1:]\n",
    "y_train_decoder_target_data = onehot_encode(y_train_decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train decoder target vs orig decoder target: (800, 30) (20000, 55)\n",
      "y_train decoder target data vs orig decoder data: (800, 30, 28) (20000, 55, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train decoder target vs orig decoder target:\", y_train_decoder_target_seq.shape, decoder_target_seq.shape)\n",
    "print(\"y_train decoder target data vs orig decoder data:\", y_train_decoder_target_data.shape, decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4NJTzgpMvlk",
    "outputId": "e3357cc7-bb1b-4c81-d754-b4741132bfc0"
   },
   "outputs": [],
   "source": [
    "# x_tr_encoder_input_seq, new_input_token_index = text2sequences(max_encoder_seq_length, x_tr)\n",
    "# y_tr_decoder_input_seq, new_target_token_index = text2sequences(max_decoder_seq_length, y_tr)\n",
    "\n",
    "# x_tr_input_data = onehot_encode(x_tr_encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "# y_tr_input_data = onehot_encode(y_tr_decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "# x_val_encoder_input_seq, _ = text2sequences(max_encoder_seq_length, x_val)\n",
    "# x_val_input_data = onehot_encode(x_val_encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "# y_val_decoder_input_seq, _ = text2sequences(max_decoder_seq_length, y_val)\n",
    "# y_val_input_data = onehot_encode(y_val_decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "# y_tr_decoder_target_seq = numpy.zeros(y_tr_decoder_input_seq.shape)\n",
    "# y_tr_decoder_target_seq[:, 0:-1] = y_tr_decoder_input_seq[:, 1:]\n",
    "# y_tr_decoder_target_data = onehot_encode(y_tr_decoder_target_seq, \n",
    "#                                     max_decoder_seq_length, \n",
    "#                                     num_decoder_tokens)\n",
    "\n",
    "# print('shape of x_tr_encoder_input_seq: ' + str(x_tr_encoder_input_seq.shape))\n",
    "# print('shape of new_token_index: ' + str(len(new_input_token_index)))\n",
    "# print('shape of x_tr_input_data: ' + str(x_tr_input_data.shape))\n",
    "\n",
    "# print('shape of x_val_encoder_input_seq: ' + str(x_val_encoder_input_seq.shape))\n",
    "# print('shape of new_token_index: ' + str(len(new_input_token_index)))\n",
    "# print('shape of x_val_input_data: ' + str(x_val_input_data.shape))\n",
    "\n",
    "# print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "# print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjCh7KcFvP4A"
   },
   "source": [
    "### 5.2 Retrain your previous Bidirectional LSTM model with training and validation data and tune the parameters (learning rate, optimizer, etc) based on validation score. (25 points)\n",
    "\n",
    "1. Use the model structure in section 3 to train a new model with new training and validation datasets.\n",
    "2. Based on validation BLEU score or loss to tune parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 27\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 512), (None, 583680      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 512)          0           bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 512)          0           bidirectional_3[0][2]            \n",
      "                                                                 bidirectional_3[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 583,680\n",
      "Trainable params: 583,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "# set the LSTM layer\n",
    "encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "                                  dropout=0.5, name='encoder_lstm'))\n",
    "_, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_h, state_c],\n",
    "                      name='encoder')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,122,332\n",
      "Trainable params: 1,122,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inputs of the decoder network\n",
    "decoder_input_h = Input(shape=(latent_dim*2,), name='decoder_input_h')\n",
    "decoder_input_c = Input(shape=(latent_dim*2,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, \n",
    "                    return_state=True, dropout=0.5, name='decoder_lstm')\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, \n",
    "                                                      initial_state=[decoder_input_h, decoder_input_c])\n",
    "\n",
    "# set the dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                      outputs=[decoder_outputs, state_h, state_c],\n",
    "                      name='decoder')\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1107968     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 28)     14364       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,706,012\n",
      "Trainable params: 1,706,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ours vs encoder_input_data (800, 9, 28) (20000, 18, 28)\n",
      "shape of ours vs decoder_input_data (800, 30, 28) (20000, 55, 30)\n",
      "shape of ours vs decoder_target_data (800, 30, 28) (20000, 55, 30)\n"
     ]
    }
   ],
   "source": [
    "print('shape of ours vs encoder_input_data', x_train_input_data.shape, encoder_input_data.shape)\n",
    "print('shape of ours vs decoder_input_data', y_train_input_data.shape, decoder_input_data.shape)\n",
    "print('shape of ours vs decoder_target_data', y_train_decoder_target_data.shape, decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQl5nem3VpzV",
    "outputId": "9519a5b1-9d07-4366-f640-7b1e93ba6b84",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "10/10 [==============================] - 7s 378ms/step - loss: 1.8623 - val_loss: 1.3916\n",
      "Epoch 2/16\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 1.3688 - val_loss: 1.3476\n",
      "Epoch 3/16\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 1.3177 - val_loss: 1.3127\n",
      "Epoch 4/16\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.2779 - val_loss: 1.2934\n",
      "Epoch 5/16\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 1.2549 - val_loss: 1.3578\n",
      "Epoch 6/16\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 1.2478 - val_loss: 1.2843\n",
      "Epoch 7/16\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 1.1896 - val_loss: 1.2378\n",
      "Epoch 8/16\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 1.1928 - val_loss: 1.1807\n",
      "Epoch 9/16\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 1.1476 - val_loss: 1.1461\n",
      "Epoch 10/16\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 1.1767 - val_loss: 1.1347\n",
      "Epoch 11/16\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 1.0831 - val_loss: 1.1011\n",
      "Epoch 12/16\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.0812 - val_loss: 1.0534\n",
      "Epoch 13/16\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 1.0590 - val_loss: 1.0572\n",
      "Epoch 14/16\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 1.0248 - val_loss: 1.0209\n",
      "Epoch 15/16\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 1.0348 - val_loss: 0.9753\n",
      "Epoch 16/16\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.9950 - val_loss: 0.9532\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([x_train_input_data, y_train_input_data],  # training data\n",
    "          y_train_decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "          batch_size=64, epochs=16, validation_split=0.2)\n",
    "\n",
    "model.save('seq2seq.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQtUcOsWvP4A"
   },
   "source": [
    "### 5.3 Evaluate the BLEU score using the test set. (15 points)\n",
    "\n",
    "1. Use trained model above to calculate the BLEU score with testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "5OCJ3uAdvP4A"
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in x_train_input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in y_train_target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 200\n",
      "Sentence: thank you True: \tgracias a ti\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "2 / 200\n",
      "Sentence: keep this True: \tguarde esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "3 / 200\n",
      "Sentence: back off True: \taparta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.25\n",
      "4 / 200\n",
      "Sentence: who came True: \tquien vino\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4166666666666667\n",
      "5 / 200\n",
      "Sentence: how awful True: \tque horror\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "6 / 200\n",
      "Sentence: stop here True: \tdetengase aqui\n",
      "\n",
      "Translation: eete e o\n",
      " Score: 0.25\n",
      "7 / 200\n",
      "Sentence: wait True: \tesperate\n",
      "\n",
      "Translation: soy aa\n",
      " Score: 0.3\n",
      "8 / 200\n",
      "Sentence: its me True: \tsoy yo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "9 / 200\n",
      "Sentence: be quiet True: \testate quieto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "10 / 200\n",
      "Sentence: i grinned True: \tsonrei\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.625\n",
      "11 / 200\n",
      "Sentence: stand up True: \tparate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "12 / 200\n",
      "Sentence: who paid True: \tquien pago\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4166666666666667\n",
      "13 / 200\n",
      "Sentence: im first True: \tyo voy primero\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.25\n",
      "14 / 200\n",
      "Sentence: lie low True: \tpasa desapercibido\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.25\n",
      "15 / 200\n",
      "Sentence: answer me True: \trespondeme\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.3333333333333333\n",
      "16 / 200\n",
      "Sentence: attack True: \tal ataque\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "17 / 200\n",
      "Sentence: move over True: \tdeja sitio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "18 / 200\n",
      "Sentence: goodbye True: \tchau\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.16666666666666669\n",
      "19 / 200\n",
      "Sentence: fire True: \tincendio\n",
      "\n",
      "Translation: soy aa\n",
      " Score: 0.2\n",
      "20 / 200\n",
      "Sentence: i fell True: \tme cai\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "21 / 200\n",
      "Sentence: go on True: \tcontinue\n",
      "\n",
      "Translation: soy aara\n",
      " Score: 0.2\n",
      "22 / 200\n",
      "Sentence: save tom True: \tsalva a tom\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.38461538461538464\n",
      "23 / 200\n",
      "Sentence: call tom True: \tllamenlo a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3888888888888889\n",
      "24 / 200\n",
      "Sentence: cheer up True: \tanimate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4444444444444444\n",
      "25 / 200\n",
      "Sentence: let us in True: \tdejanos entrar\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.375\n",
      "26 / 200\n",
      "Sentence: im loved True: \tsoy amada\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "27 / 200\n",
      "Sentence: relax True: \ttomatelo con soda\n",
      "\n",
      "Translation: soy aara\n",
      " Score: 0.2631578947368421\n",
      "28 / 200\n",
      "Sentence: no way True: \timposible\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "29 / 200\n",
      "Sentence: im a man True: \tsoy un hombre\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "30 / 200\n",
      "Sentence: go True: \tvete\n",
      "\n",
      "Translation: aara\n",
      " Score: 0.16666666666666669\n",
      "31 / 200\n",
      "Sentence: its a tv True: \tes un televisor\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4117647058823529\n",
      "32 / 200\n",
      "Sentence: i hit tom True: \tgolpee a tom\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3571428571428572\n",
      "33 / 200\n",
      "Sentence: did i win True: \tgane\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "34 / 200\n",
      "Sentence: im naked True: \testoy desnudo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4666666666666667\n",
      "35 / 200\n",
      "Sentence: i use it True: \tyo lo uso\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "36 / 200\n",
      "Sentence: i saw you True: \tte vi\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5714285714285714\n",
      "37 / 200\n",
      "Sentence: slow down True: \tquieto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "38 / 200\n",
      "Sentence: humor me True: \thazme el favor\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.25\n",
      "39 / 200\n",
      "Sentence: put it on True: \tpontelo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5555555555555556\n",
      "40 / 200\n",
      "Sentence: take it True: \tcogelo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "41 / 200\n",
      "Sentence: its ok True: \testa bien\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "42 / 200\n",
      "Sentence: that hurt True: \tesa dolio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "43 / 200\n",
      "Sentence: feel this True: \ttiente esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5384615384615384\n",
      "44 / 200\n",
      "Sentence: i get you True: \tte entiendo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "45 / 200\n",
      "Sentence: push it True: \tempujenlo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "46 / 200\n",
      "Sentence: im first True: \tme toca primero\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.29411764705882354\n",
      "47 / 200\n",
      "Sentence: it snowed True: \tnevo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.6666666666666666\n",
      "48 / 200\n",
      "Sentence: call us True: \tllamanos\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "49 / 200\n",
      "Sentence: drive on True: \tcontinua\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "50 / 200\n",
      "Sentence: calm down True: \tcalmense\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "51 / 200\n",
      "Sentence: get lost True: \tvete de aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "52 / 200\n",
      "Sentence: am i fat True: \testoy gorda\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "53 / 200\n",
      "Sentence: skip it True: \tsaltatelo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "54 / 200\n",
      "Sentence: im hurt True: \testoy herido\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "55 / 200\n",
      "Sentence: keep this True: \tguarden esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "56 / 200\n",
      "Sentence: be strong True: \tse fuerte\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "57 / 200\n",
      "Sentence: tom ate True: \ttom comio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "58 / 200\n",
      "Sentence: tell me True: \tdecidmelo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2727272727272727\n",
      "59 / 200\n",
      "Sentence: take this True: \ttoma esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "60 / 200\n",
      "Sentence: find tom True: \tencuentrelo a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "61 / 200\n",
      "Sentence: you lost True: \tha perdido usted\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "62 / 200\n",
      "Sentence: forget me True: \tolvidame\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.3\n",
      "63 / 200\n",
      "Sentence: come in True: \tentre\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5714285714285714\n",
      "64 / 200\n",
      "Sentence: hold on True: \tresiste\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4444444444444444\n",
      "65 / 200\n",
      "Sentence: im back True: \the vuelto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "66 / 200\n",
      "Sentence: hold it True: \tsostenganla\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "67 / 200\n",
      "Sentence: so long True: \thasta luego\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "68 / 200\n",
      "Sentence: try some True: \tpruebalo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "69 / 200\n",
      "Sentence: push it True: \tempujenla\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2727272727272727\n",
      "70 / 200\n",
      "Sentence: after you True: \tdespues de vosotras\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "71 / 200\n",
      "Sentence: i see tom True: \tveo a tom\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "72 / 200\n",
      "Sentence: back off True: \tretrocede\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "73 / 200\n",
      "Sentence: i used it True: \tlo use\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.625\n",
      "74 / 200\n",
      "Sentence: push it True: \tempujadlo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2727272727272727\n",
      "75 / 200\n",
      "Sentence: rest here True: \tdescansa aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "76 / 200\n",
      "Sentence: im back True: \testoy de vuelta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.35294117647058826\n",
      "77 / 200\n",
      "Sentence: i had it True: \tlo tenia\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.6\n",
      "78 / 200\n",
      "Sentence: im tired True: \tyo estoy cansado\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3888888888888889\n",
      "79 / 200\n",
      "Sentence: catch him True: \tatrapalo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "80 / 200\n",
      "Sentence: go inside True: \tentra\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.5714285714285714\n",
      "81 / 200\n",
      "Sentence: shut up True: \tcerra el pico\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.26666666666666666\n",
      "82 / 200\n",
      "Sentence: its big True: \tes grande\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "83 / 200\n",
      "Sentence: i get by True: \tme las arreglo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3125\n",
      "84 / 200\n",
      "Sentence: take mine True: \tcoge el mio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.30769230769230765\n",
      "85 / 200\n",
      "Sentence: nice shot True: \tbuen tiro\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "86 / 200\n",
      "Sentence: i fainted True: \tquede inconsciente\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3499999999999999\n",
      "87 / 200\n",
      "Sentence: join us True: \tse parte nuestra\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "88 / 200\n",
      "Sentence: taste it True: \tpruebalo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "89 / 200\n",
      "Sentence: stand up True: \tde pie\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "90 / 200\n",
      "Sentence: leave now True: \tahora marchate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3125\n",
      "91 / 200\n",
      "Sentence: it helps True: \teso ayuda\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "92 / 200\n",
      "Sentence: stand by True: \tpreparate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2727272727272727\n",
      "93 / 200\n",
      "Sentence: read this True: \tlea esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.6\n",
      "94 / 200\n",
      "Sentence: wake up True: \tdespierta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "95 / 200\n",
      "Sentence: feel this True: \ttenta esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5833333333333334\n",
      "96 / 200\n",
      "Sentence: she runs True: \tella corre\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "97 / 200\n",
      "Sentence: you lost True: \tperdio usted\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "98 / 200\n",
      "Sentence: no way True: \tminga\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "99 / 200\n",
      "Sentence: humor me True: \tcomplaceme\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.25\n",
      "100 / 200\n",
      "Sentence: forget me True: \tolvidate de mi\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.3125\n",
      "101 / 200\n",
      "Sentence: im happy True: \tsoy feliz\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "102 / 200\n",
      "Sentence: leave tom True: \tdejelo a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "103 / 200\n",
      "Sentence: go now True: \tve ya\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "104 / 200\n",
      "Sentence: loosen it True: \tsueltalo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "105 / 200\n",
      "Sentence: find tom True: \tencontralo a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3499999999999999\n",
      "106 / 200\n",
      "Sentence: feel this True: \ttienten esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "107 / 200\n",
      "Sentence: hes fast True: \tel es veloz\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.38461538461538464\n",
      "108 / 200\n",
      "Sentence: im lucky True: \ttengo suerte\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "109 / 200\n",
      "Sentence: slow down True: \tmas despacio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3571428571428572\n",
      "110 / 200\n",
      "Sentence: i moved True: \tme he mudado\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "111 / 200\n",
      "Sentence: listen True: \tescucha\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "112 / 200\n",
      "Sentence: birds fly True: \tlos pajaros vuelan\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "113 / 200\n",
      "Sentence: keep out True: \tno entrar\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "114 / 200\n",
      "Sentence: toms up True: \ttom se ha levantado\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "115 / 200\n",
      "Sentence: see you True: \thasta luego\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "116 / 200\n",
      "Sentence: i forgot True: \tlo olvide\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "117 / 200\n",
      "Sentence: we agree True: \testamos de acuerdo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "118 / 200\n",
      "Sentence: i did it True: \tlo hice\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4444444444444444\n",
      "119 / 200\n",
      "Sentence: sit here True: \tsentate aca\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "120 / 200\n",
      "Sentence: tom lied True: \ttom mintio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4166666666666667\n",
      "121 / 200\n",
      "Sentence: im dying True: \tme estoy muriendo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3684210526315789\n",
      "122 / 200\n",
      "Sentence: loosen it True: \taflojala\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2\n",
      "123 / 200\n",
      "Sentence: ask him True: \tpreguntale\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "124 / 200\n",
      "Sentence: shes hot True: \testa que cruje\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3125\n",
      "125 / 200\n",
      "Sentence: get up True: \tlevanta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4444444444444444\n",
      "126 / 200\n",
      "Sentence: its ours True: \tes la nuestra\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "127 / 200\n",
      "Sentence: i agreed True: \tconvine\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4444444444444444\n",
      "128 / 200\n",
      "Sentence: we lost True: \tperdimos\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "129 / 200\n",
      "Sentence: she walks True: \tella anda\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "130 / 200\n",
      "Sentence: come over True: \tvenid aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "131 / 200\n",
      "Sentence: stand by True: \tun momento\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "132 / 200\n",
      "Sentence: dont run True: \tno corras\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "133 / 200\n",
      "Sentence: can we go True: \tpodemos marcharnos\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.25\n",
      "134 / 200\n",
      "Sentence: i kneeled True: \tme arrodille\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "135 / 200\n",
      "Sentence: ill stop True: \tlo dejare\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "136 / 200\n",
      "Sentence: dont cry True: \tno llore\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "137 / 200\n",
      "Sentence: cheer up True: \tvenga\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "138 / 200\n",
      "Sentence: run True: \tcorred\n",
      "\n",
      "Translation: soyaaa\n",
      " Score: 0.25\n",
      "139 / 200\n",
      "Sentence: try some True: \tpruebe un poco\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3125\n",
      "140 / 200\n",
      "Sentence: leave now True: \tahora largate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "141 / 200\n",
      "Sentence: no way True: \tde ninguna manera\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.21052631578947367\n",
      "142 / 200\n",
      "Sentence: do it now True: \thazlo ahora\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.23076923076923078\n",
      "143 / 200\n",
      "Sentence: tom spit True: \ttom escupio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "144 / 200\n",
      "Sentence: push it True: \tempujelo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "145 / 200\n",
      "Sentence: wake up True: \tdespertate\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "146 / 200\n",
      "Sentence: im fine True: \testoy perfectamente\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "147 / 200\n",
      "Sentence: i failed True: \tfalle\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "148 / 200\n",
      "Sentence: i refuse True: \tme niego\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "149 / 200\n",
      "Sentence: sorry True: \tdisculpa\n",
      "\n",
      "Translation: soy aeno\n",
      " Score: 0.3\n",
      "150 / 200\n",
      "Sentence: hurry True: \tdaos prisa\n",
      "\n",
      "Translation: soy aeno\n",
      " Score: 0.4166666666666667\n",
      "151 / 200\n",
      "Sentence: tell me True: \tcuentame\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "152 / 200\n",
      "Sentence: go on True: \tcontinua\n",
      "\n",
      "Translation: soy aara\n",
      " Score: 0.3\n",
      "153 / 200\n",
      "Sentence: i stayed True: \tme quede\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3\n",
      "154 / 200\n",
      "Sentence: ill walk True: \tandare\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "155 / 200\n",
      "Sentence: stop that True: \tpara eso\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "156 / 200\n",
      "Sentence: take this True: \ttoma esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "157 / 200\n",
      "Sentence: its fun True: \tes divertido\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "158 / 200\n",
      "Sentence: hi guys True: \thola por aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2\n",
      "159 / 200\n",
      "Sentence: keep this True: \tguarda esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.46153846153846156\n",
      "160 / 200\n",
      "Sentence: she died True: \tella murio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "161 / 200\n",
      "Sentence: answer me True: \trespondanme\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.30769230769230765\n",
      "162 / 200\n",
      "Sentence: take over True: \tencargate tu\n",
      "\n",
      "Translation: eete eno\n",
      " Score: 0.3571428571428572\n",
      "163 / 200\n",
      "Sentence: i can run True: \tse correr\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "164 / 200\n",
      "Sentence: keep warm True: \tmantengase caliente\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "165 / 200\n",
      "Sentence: say hello True: \tdeci hola\n",
      "\n",
      "Translation: eete e o\n",
      " Score: 0.36363636363636365\n",
      "166 / 200\n",
      "Sentence: i can go True: \tpuedo ir\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "167 / 200\n",
      "Sentence: find tom True: \tencuentrenlo a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3181818181818182\n",
      "168 / 200\n",
      "Sentence: shes hot True: \tella es candente\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "169 / 200\n",
      "Sentence: have fun True: \tpasala bien\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.38461538461538464\n",
      "170 / 200\n",
      "Sentence: im deaf True: \tsoy sordo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.36363636363636365\n",
      "171 / 200\n",
      "Sentence: shes hot True: \testa buena\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "172 / 200\n",
      "Sentence: im sorry True: \tlo siento\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.6363636363636364\n",
      "173 / 200\n",
      "Sentence: come on True: \torale\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "174 / 200\n",
      "Sentence: its cool True: \testa frio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "175 / 200\n",
      "Sentence: speak up True: \thabla mas fuerte\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2777777777777778\n",
      "176 / 200\n",
      "Sentence: ill stay True: \tyo me quedo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.30769230769230765\n",
      "177 / 200\n",
      "Sentence: lock it True: \techa el cerrojo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.23529411764705885\n",
      "178 / 200\n",
      "Sentence: get to it True: \tponte a ello\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "179 / 200\n",
      "Sentence: lets try True: \tintentemoslo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "180 / 200\n",
      "Sentence: come in True: \tentren\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: este eno\n",
      " Score: 0.5\n",
      "181 / 200\n",
      "Sentence: im angry True: \testoy enojada\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4666666666666667\n",
      "182 / 200\n",
      "Sentence: thats me True: \tese soy yo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4166666666666667\n",
      "183 / 200\n",
      "Sentence: kiss tom True: \tbesa a tomas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.42857142857142855\n",
      "184 / 200\n",
      "Sentence: dont go True: \tno te vayas\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5384615384615384\n",
      "185 / 200\n",
      "Sentence: take this True: \ttomen esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5833333333333334\n",
      "186 / 200\n",
      "Sentence: read this True: \tlee esto\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.6\n",
      "187 / 200\n",
      "Sentence: i like it True: \tme gusta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "188 / 200\n",
      "Sentence: its his True: \tes suyo\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5555555555555556\n",
      "189 / 200\n",
      "Sentence: im broke True: \testoy sin blanca\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3888888888888889\n",
      "190 / 200\n",
      "Sentence: hold on True: \tsujeta\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "191 / 200\n",
      "Sentence: its here True: \testa aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "192 / 200\n",
      "Sentence: its good True: \testa bien\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5454545454545454\n",
      "193 / 200\n",
      "Sentence: im lost True: \testoy perdida\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.4\n",
      "194 / 200\n",
      "Sentence: run True: \tcorre\n",
      "\n",
      "Translation: soyaaa\n",
      " Score: 0.2857142857142857\n",
      "195 / 200\n",
      "Sentence: im blind True: \tsoy ciega\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.45454545454545453\n",
      "196 / 200\n",
      "Sentence: i am here True: \testoy aqui\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.5\n",
      "197 / 200\n",
      "Sentence: i mean it True: \thablo en serio\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.375\n",
      "198 / 200\n",
      "Sentence: i moved True: \tme mude\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.3333333333333333\n",
      "199 / 200\n",
      "Sentence: go get it True: \tid a por ello\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.26666666666666666\n",
      "200 / 200\n",
      "Sentence: get tom True: \tagarra a tom\n",
      "\n",
      "Translation: este eno\n",
      " Score: 0.2857142857142857\n",
      "Average BLEU Score using the test set: 0.3914687505262195\n"
     ]
    }
   ],
   "source": [
    "score = 0;\n",
    "for i, sentence in enumerate(x_test):\n",
    "  print(i+1, \"/\", len(x_test))\n",
    "  print(\"Sentence:\", sentence, \"True:\", y_test[i])\n",
    "  input_sequence, _ = text2sequences(max_encoder_seq_length, [sentence])\n",
    "  input_x = onehot_encode(input_sequence, max_encoder_seq_length, num_encoder_tokens)\n",
    "  translated_sentence = decode_sequence(input_x)\n",
    "  print(\"Translation:\", translated_sentence, \"Score:\", sentence_bleu(translated_sentence,y_test[i],[1]))\n",
    "  score += sentence_bleu(translated_sentence, y_test[i], [1])\n",
    "score /= len(x_test)\n",
    "print(\"Average BLEU Score using the test set:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
